# Coding Agent Infrastructure - Requirements Clarification

## Core Use Cases
Please rank these use cases by importance (1-5, 1 being most important):

**Single Agent Tasks:**
- [5] Run one agent on isolated feature branch
- [4] Debug/fix specific issue with agent
- [5] Generate code/documentation with agent

**Multi-Agent Workflows:**
- [2] A/B test: 3 agents solve same problem, pick best solution
- [4] Parallel work: Multiple agents on different parts of same project
- [3] Collaborative: Agents work together on single complex task
- [4] Review/QA: One agent codes, another reviews

## Architecture Decision: Container Strategy

**Option A: Per-Agent Containers**
- Pros: Complete isolation, no resource conflicts
- Cons: More complex orchestration, harder agent-to-agent communication
- VSCode integration: Multiple workspace folders

**Option B: Shared Container**
- Pros: Simpler orchestration, easier agent communication, single VSCode attach
- Cons: Resource negotiation needed, potential conflicts

**Your preference and reasoning:**
[Jörn]
- B, shared container; you gave the right pro cons: 
  - Resource negotiation is simple: the orchestrator agent prepares ports/port ranges, git worktrees, and other resource negotiation.
  - Agent-to-agent communication is simpler, as they can share the same network.
  - VSCode integration is simpler, we can just mount e.g. HOST:~/workspaces as /workspaces/ and automatically all folders are available in the same VSCode workspace.
  - we can share the ~/{.claude,.gemini,.config/gh,.cloudflared} oauth more easily; the base agents all support per-worktree configs as well, so we can let them develop their own configs while sharing a unique resource (oauth).
  - probably each agent should have a unique file (gitignored) with instructions generated by the orchestrator agent, including
    - ports, unique names/ids, other resource mappings (e.g. the branch name, the git worktree folder name, etc.)
    - the agent can finish setup, or the orchestrator can finish setup for the agent. Unsure what's cleaner, easy to refactor though; leaning towards letting the orchestrator prepare the agent environment (or at least the main setup, not all details).
    - e.g. maybe orchestrator runs "git worktree add", then writes to `../<dir>/{prompt.md, .env}` where .env is for resource definitions that are automatically used by e.g. a webserver or a telemetry otlp collector process or the claude processes. And prompt.md is the instructions for the agent. Then the agent is spawned, probably via some central service that tracks agents and facilitates communication, exposed as e.g. `mcp__agent_spawn(dir=../<dir>, name=<name>, prompt_file=../<dir>/prompt.md, env_file=../<dir>/.env)` or similar. The spawned agent inherits the .env envvars (which e.g. tell "claude" where to send telemetry), and the agent's Bash() commands also inherit .env, e.g. the webserver will have the PORT envvar set.
    - communication then is done via sth like `mcp__mail_send(from=<name>, to=[<name1>, <name2>], subject=<subject>, body=<body>)` and a mix of
    - `mcp__mail_inbox(to=<name>, from?=<name>, subject_contains?=<keyword>, since_hours_ago?=<hours>)` to get the inbox of an agent, which is a list of single-lines, and `mcp__mail_read(id=<id>)` to read a specific mail.
    - We can use claude code hooks to furthermore automatically inform agents when they receive a mail, i.e. they get a brief message `you got mail:\n<single-lines>` even while they are working, i.e. in between their normal tool calls/messages we insert the mail message, so they can react to it or wait until they finish their current task.

## Resource Management
How should agents handle:
- **Port conflicts:** Auto-assign ports vs. predefined ranges vs. other?
- **File conflicts:** Git worktrees vs. separate checkouts vs. file locking?
- **CPU/Memory:** Per-agent limits vs. shared pool?
- **Network:** Shared vs. isolated networks?

[Jörn] I suggest:
- assign ports in a .env file written by the central orchestrator agent.
- git worktrees for file management, the orchestrator agent then either merges or accepts PRs
- CPU/Memory never were a bottleneck so far, YAGNI says to not bother thinking much about them yet.
- Network: shared network, isolation is too complex afaict(?)

## Sandboxing Requirements
What should agents NOT be able to do:
- [ ] Modify files outside their workspace
- [ ] Access network (except specific APIs)
- [ ] Install system packages
- [ ] Access other agent workspaces
- [ ] Run privileged commands
- [ ] Other: [specify]

[Jörn]
- Agents are quite wise if prompted right, i.e. we need to tell them that they should not kill processes to free up *non-owned* ports, but rather fix that their own local command uses an occupied port (e.g. editing .env? exporting a new envvar?).
- Network access is fine, e.g. for websearch, puppeteer browsing of their own webapp, etc.
- The big problem with installing new deps is that they get lost on container rebuild, so it is fine if agents install stuff, but they should edit their (local copy) of the dockerfile to add the new deps, so that once merged + rebuilt, the new deps are available in the environment as well.
- Read access to other agent workspaces is fine; write access is usualyl not an issue since agents don't mess with that; I don't see an easy way to prevent it, so let's mark that as "too difficult to bother with"
- sudo can be useful! agents know how to use it, and that is fine.
- afaict they are inside a docker container and even with sudo cannot change the *host* system, which is the one critical system I am truly worried about
- i.e. on HOST there are passwords, keys, and valuable non-backuped files I wouldn't want the agents to read nor write to. We simply don't mount those into the container though, so usually that's enough (unless agents are taken over and start hacking through the docker ?)

## Human Interface
How do you want to:
- **Monitor agents:** Logs, web dashboard, CLI status, other?
- **Intervene:** Pause/resume, inject commands, modify agent state?
- **View results:** VSCode, web interface, CLI diffs, other?

[Jörn]
- Classic way is to use VSCode terminals and manually start the agents with a handtyped "claude" command, which opens the TUI
- Since I'd like automatic spawning of agents though, I suggest to implement a simple web dashboard that shows the agents, their status and outputs. Readonly is okay for now. I just need to know when agents are done with their tasks, I don't usualyl want to intervene.
- For the orchestrator agent, I maintain a open terminal with the "claude" command running, so I have full access to the claude TUI and can chat with the agent directly.
- The orchestrator agent can intervene with the spawned agents by sending them mails. Mayybe there also should be mcp__agent_stop and mcp__agent_inject_message commands for more aggressive control that mimicks how the TUI works, let's mark that for later.
- I will view results in VSCode (i.e. I will open files in the worktree and read through them, open up diffs between branches, commits, changes, etc., run terminal commands in a worktree after sourcing the local .env file, etc.)
- Viewing agent status/chat history in a web interface sounds nice as well
- For now we can actually focus on the classic way, i.e. mcp__agent_spawn only sets up the environment and tells the orchestrator to tell me to open a new terminal, cd into the directory, source .env and start `claude` manually with a fixed command such as `cd ../<path> && source .env && claude --dangerously-skip-permissions "@prompt.md"` (which enables the full-autonomy mode and preloads the prompt.md file into the agent so that it immediately starts working on the task). We omit the `--print` flag bc we want the TUI in the terminal. This way (the classic way) we can for now skip any web interface and scripted agent process management; agent starts+stops are done manually by me instead, which is okay (potentially even okay forever, it's really not a lot of time required).
- Now that I think about it, we also need a mcp server that manages background processes, since the Bash() tool is bad at that. Sth that starts a background process, and allows grep-ing its output so far, stopping it, etc. Importantly, we want to track "ownership" over background processes, and allow listing them, so that cleanup is easier than with anonymous "uv run ./scripts/webserver.py" processes that aren't obviously related to a specific worktree or sth at first glance.

## Integration Requirements
- **Version control:** Git hooks, automatic commits, branch management?
- **CI/CD:** Trigger tests, deployment, notifications?
- **External tools:** Docker, k8s, cloud services?

[Jörn]
- git, precommit hook for local CI, github's CI/CD for remote checks, PR management, etc.
- no tool for branch management, that is too much cognitive overhead, instead agents use Bash(git branch) or Bash(git worktree) to manage branches and worktrees directly. Now that I think about it, we should also omit the mcp__agent_spawn command for now and instead let the orchestrator agent simply run above commands (with guidance, i.e. a full workflow written down somewhere to imitate)
- I suggest docker since I am familiar with it
- We *may* in the future want to use github codespaces if I am traveling, but not right now, since they are finicky

## Scale
- **Typical usage:** How many agents simultaneously?
- **Max agents:** Upper bound you need to support?
- **Project size:** Small scripts vs. large codebases?

[Jörn]
- Scale: 50% of wall time: 1 agent, 25%: 3 agents, 25%: 5 agents
- Max agents: Anything >5 agents is too fragile/wasteful (and we'd hit rate limits quickly)
- Largest project i envision is a macroeconomic simulation with ~25 datasets and ~10 papers implemented, reproduced, and then merged into a single, more accurate/wholesome/global model
- Typical project is: webserver for a research team of 5 people who want to run ML experiments and view the results as a single table/dashboard with a submit page to start new jobs
- Most projects have (e.g. inherited from this repo) a few scripts, e.g. single-file (uv, pep 723, fastmcp) mcp servers, sh scripts for automation with validation of common workflows, and a bunch of .md documentation, and a bunch of files for the environment setup (.devcontainer ? or just a environment/Dockerfile if we don't use vscode devcontainers but rather just docker directly)

## Questions for You:
1. Do you want this to be a CLI tool, web service, or both?
2. Should agents be able to spawn other agents?
3. How important is persistence across restarts?
4. Do you need agent-to-agent communication primitives?
5. What's your budget for complexity vs. features?

[Jörn]
- 1. confused why you ask. Mostly we have
  - text with instructions and examples for the agents so they know how to work best and what workflows we designed for them and what the environment they are in is like
  - environment setup (Dockerfile, commands/scripts to attach vscode, etc.)
- for now I manually spawn agents, and the orchestrator agent (orchestrator=just a rule for a normal agent) just setups the worktree and .env file and prompt.md file.
- we will develop fast, so restarts/rebuilds of the docker are common; i suggest to mount ~/{.claude,.gemini,.config/gh,.cloudflared} into volumes for that reason, so they persist on the same HOST at least (we cannot commit them as they contain secrets)
- similarly mount/link+mount .bash_history, and anything else that comes to mind
- mail mcp server with a central exchange (e.g. /workspaces/.mail/{id}.json files) is enough
- we need to make the project maintainable *by* coding agents, so complexity should be low, and documentation detailed and explicit and specific/actionable (examples, spell out implications, constraints, present common troubleshooting solutions, etc.); more on that once you ask me to write down what I know about how agents differ from humans, and also what I know about human developers (e.g. how to best onboard a experienced senior developer who knows most concepts and just needs to know what choices this repo made and what **commonly known** conventions it thus follows; idiosyncrasies are high cognitive load, while well-known patterns are low cognitive load for such an experienced developer, and this is the same for AI agents)
- I suggest to iterate fast, i.e. get into a MVP state asap, and then continue from there feature by feature.